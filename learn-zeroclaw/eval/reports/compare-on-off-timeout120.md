# RE-TRAC 开关对照结论（timeout=120s）

## 评测口径

- 任务集：`baseline_tasks_full.jsonl`（20 题）
- 重复次数：`repeats=3`（共 60 次）
- 网关超时：`REQUEST_TIMEOUT_SECS = 120`
- 对照组：
  - ON：`trajectory_compression_enabled = true`
  - OFF：`trajectory_compression_enabled = false`

数据来源：

- ON 汇总：`compare-on-timeout120-summary.md`
- OFF 汇总：`compare-off-timeout120-summary.md`

---

## 核心指标对比

| 指标 | ON（压缩开启） | OFF（压缩关闭） | 变化 |
|---|---:|---:|---:|
| Success rate | 100.00% | 93.33% | **+6.67pp** |
| Avg latency | 28013.73 ms | 31348.20 ms | **-3334.47 ms** |
| P95 latency | 53789 ms | 120003 ms | **显著下降** |
| Avg iterations | 1.63 | 1.62 | +0.01 |
| Avg tool calls | 0.78 | 0.82 | -0.04 |

---

## 结果解读

1. **成功率提升明显**：开启轨迹压缩后，在同口径下成功率从 93.33% 提升到 100%。
2. **长尾时延改善显著**：P95 从 120s 附近降到 53.8s，说明“超时长尾”明显减少。
3. **工具调用略下降**：平均工具调用从 0.82 降到 0.78，符合“更聚焦探索”的方向。
4. **迭代次数基本持平**：性能提升主要来自每轮决策质量/稳定性改善，而不是单纯减少迭代轮次。

---

## 完成记录级详细对比（逐条对齐）

### 对齐方式

- 使用 `compare-on-timeout120-raw.jsonl` 与 `compare-off-timeout120-raw.jsonl`。
- 以 `(task_id, run_index)` 一一配对比较（总计 60 组），避免只看均值导致的信息丢失。
- 逐条比较优先级：
  1. 是否完成（`ok`）
  2. 延迟（`latency_ms`，差异 >100ms 视为有效）
  3. expectation 规则化参考分（1-5）

### 逐条胜负统计（60 组）

- ON 胜：`29`
- OFF 胜：`30`
- 平局：`1`

> 解释：逐条胜负接近，说明在“双方都成功”的样本里，OFF 在部分简单问题上仍可能更短、更直接；  
> 但这不与“总体 ON 更优”矛盾，因为总体差异主要由关键失败样本驱动。

### 关键任务对比（按任务聚合）

提升最明显（ON 相比 OFF）：

- `baseline-010`（频率与异常处理）
  - 质量分：`3.844 vs 1.333`（+2.511）
  - 成功次数：`3/3 vs 1/3`
  - 平均时延：`56031ms vs 91692ms`
- `baseline-013`（pair token / Authorization）
  - 质量分：`4.711 vs 2.511`（+2.200）
  - 成功次数：`3/3 vs 2/3`
  - 平均时延：`20299ms vs 68712ms`
- `baseline-018`（history 比对与幂等）
  - 质量分：`3.267 vs 2.222`（+1.044）
  - 成功次数：`3/3 vs 2/3`
  - 平均时延：`23315ms vs 52898ms`

存在回退风险（需复核）：

- `smoke-005`（去重/停止/熔断）
  - 质量分：`2.400 vs 3.267`（-0.867）
- `baseline-008`（失败后的替代方案）
  - 质量分：`3.844 vs 4.422`（-0.578）
- `baseline-011`（token/上下文压缩策略）
  - 质量分：`4.422 vs 5.000`（-0.578）

### 关键样本（ON 成功而 OFF 超时失败）

- `baseline-010` run=1：ON `38161ms` 完成；OFF `120003ms` 超时失败
- `baseline-010` run=3：ON `39338ms` 完成；OFF `120003ms` 超时失败
- `baseline-013` run=2：ON `28652ms` 完成；OFF `120005ms` 超时失败
- `baseline-018` run=1：ON `22882ms` 完成；OFF `120005ms` 超时失败

### 小结（记录级视角）

- “逐条胜负接近”是正常现象，反映的是简单样本上的短答差异。
- “总体 ON 更优”由关键任务的**失败转成功**和**长尾超时收敛**驱动，这与工程目标（稳定性/可交付）一致。

---

## 结论

在当前 ZeroClaw 配置与任务集下，`RE-TRAC-lite`（trajectory compression）在 **稳定性、成功率、长尾时延** 三个维度均优于关闭状态，具备继续推进的工程价值。

---

## AI 规则化参考评估（基于 expectation）

> 说明：此处为 AI 规则化参考分，不是人工金标准。  
> 评分逻辑基于任务 `expectation` 的关键词覆盖、结构完整度（步骤/清单）、可执行性信号（验证/检查/流程等）。

### 参考总分（1-5）

| 指标 | ON（压缩开启） | OFF（压缩关闭） | 变化 |
|---|---:|---:|---:|
| 平均分 | 4.005 | 3.854 | **+0.152** |
| P25 | 3.267 | 3.267 | 0 |
| P50 | 4.133 | 4.133 | 0 |
| P75 | 5.000 | 5.000 | 0 |

### 参考观察

1. **质量呈小幅正向提升**：平均参考分提高 `+0.152`，与成功率/长尾时延改善方向一致。  
2. **提升最明显任务**：
   - `baseline-010`（调度模板）
   - `baseline-013`（认证流程）
   - `baseline-018`（幂等验证）
3. **可能回退任务**：
   - `smoke-005`（降低工具调用策略）
   - `baseline-011`（降 token 工程策略）
   - `baseline-008`（失败熔断策略）

### 使用边界

- 该分数用于“趋势判断”和“优先复核排序”，不替代人工质量评审。  
- 最终质量结论建议结合 `quality-review-template.md` 的人工抽检结果。

---

## 下一步建议

1. 将该对照流程固化为标准回归评测（每次核心改动后复跑）。
2. 引入人工质量评分（`rubric.md`）补充自动指标，避免仅凭成功率判断质量。
3. 评估是否把 120s 超时策略参数化到配置，便于不同环境调优。

---

## restart-eval 单轮样本补充（2026-02-21）

> 口径说明：该样本仅为 `baseline_tasks.jsonl`（5 题）且 `repeats=1`，用于服务重启后的冒烟观测，不与上文 60 组 ON/OFF 主对照直接混算。

- 数据文件：
  - `restart-eval-raw.jsonl`
  - `restart-eval-summary.md`
- 总体结果：
  - Success rate：`40.00%`（2/5）
  - Avg latency：`25075.20 ms`
  - P95 latency：`30004 ms`
  - Failure distribution：`http_error=3`（408 超时）
- 解读：
  - 该轮结果显示“重启后可用但稳定性仍受超时影响”，更适合作为“当次运行健康快照”，不代表 RE-TRAC 主体趋势回退。
  - 建议沿用主评测口径（20 题 × 3 次）复跑，再判断阶段性结论是否变化。
